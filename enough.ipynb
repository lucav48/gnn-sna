{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d89e3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import subprocess\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "import random\n",
    "import time\n",
    "\n",
    "def scompatt(output):\n",
    "    l = output.decode(\"utf-8\") .split(\"\\n\")\n",
    "    lambdas = [float(x) for x in l[4].split(\"LAMBDAS: \")[1].replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(\",\")]\n",
    "    accuracy = l[10].split(\"Test accuracy: \")[1].split(\", \")[0]\n",
    "    loss = l[11].split(\"Test loss: \")[1].split(\", \")[0]\n",
    "    precision = l[12].split(\"Test precision: \")[1].split(\", \")[0]\n",
    "    recall = l[13].split(\"Test recall: \")[1].split(\", \")[0]\n",
    "    return lambdas, float(accuracy) / 100, float(loss), float(precision), float(recall)\n",
    "\n",
    "def single_run(dataset, epochs, lambdas):\n",
    "    base_command_1 = \"python3 -u node_class_full.py --data \" + dataset + \" --epoch \" + str(epochs) + \" \"\n",
    "    base_command_2 = \" --layer 3 --w_att 0.001 --w_fc2 0.0 --w_fc1 0.001 --dropout 0.25 --lr_fc 0.01 --lr_att 0.01 --layer_norm 1 --dev 0 \"\n",
    "    command = base_command_1 + base_command_2 + \" --lambdas \" + lambdas\n",
    "#     print(command)\n",
    "    output = subprocess.check_output(command, shell=True)\n",
    "    return scompatt(output)\n",
    "\n",
    "def print_stuff(stuff):\n",
    "    print(\"LAMBDAS:\", stuff[0])\n",
    "    print(\"ACCURACY:\", stuff[1])\n",
    "    print(\"PRECISION:\", stuff[3])\n",
    "    print(\"RECALL:\", stuff[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c0ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "datasets = [\"cornell\", \"texas\", \"wisconsin\"]#, \"chameleon\", \"cora\"]\n",
    "all_lambdas = [\"2,3\", \"2,4\", \"2,5\", \"3,4\", \"3,5\", \"4,5\", \"2,3,4\", \"2,3,5\", \"2,4,5\", \"3,4,5\", \"2,3,4,5\"]\n",
    "\n",
    "def f(dataset, epochs, lambdas):\n",
    "    df = {}\n",
    "    output = single_run(dataset, epochs, lambdas)\n",
    "    df[\"acc\"] = output[1]\n",
    "    df[\"pre\"] = output[3]\n",
    "    df[\"rec\"] = output[4]\n",
    "    df[\"n_lambdas\"] = lambdas\n",
    "    df[\"lambdas\"] = output[0]\n",
    "#     print(\"-\" * 50)\n",
    "#     print(\"LAMBDAS:\", lambdas)\n",
    "#     print_stuff(output)\n",
    "    return df\n",
    "\n",
    "for dataset in datasets:\n",
    "    r = Parallel(n_jobs=-1)(delayed(f)(dataset, epochs, lambdas) for lambdas in all_lambdas)\n",
    "    results = {\"acc\": [], \"pre\": [], \"rec\": [], \"lambdas\": [], \"n_lambdas\":[]}\n",
    "    for x in r:\n",
    "        results[\"acc\"].append(x[\"acc\"])\n",
    "        results[\"pre\"].append(x[\"pre\"])\n",
    "        results[\"rec\"].append(x[\"rec\"])\n",
    "        results[\"lambdas\"].append(x[\"lambdas\"])\n",
    "        results[\"n_lambdas\"].append(x[\"n_lambdas\"])\n",
    "    pd.DataFrame.from_dict(results).to_csv(\"results/mega-\" + dataset + \"-\" + str(int(time.time())) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916f349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
